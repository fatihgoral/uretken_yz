import json
from pathlib import Path
from llm.gemini_client import GeminiClient

DATA_FILE = Path("progress.json")
client = GeminiClient()


def _safe_json_parse(text: str) -> dict:
    """
    LLM Ã§Ä±ktÄ±sÄ±ndan JSON bloÄŸunu gÃ¼venli ÅŸekilde ayÄ±klar
    (SADECE parse fallback)
    """
    if not text:
        raise ValueError("BoÅŸ LLM Ã§Ä±ktÄ±sÄ±")

    cleaned = text.replace("```json", "").replace("```", "").strip()
    start = cleaned.find("{")
    end = cleaned.rfind("}")

    if start == -1 or end == -1:
        raise ValueError("JSON bulunamadÄ±")

    return json.loads(cleaned[start:end + 1])


def decide_plan_intensity() -> dict:
    """
    Coordinator Agent
    - KararÄ± SADECE LLM verir
    - LLM Ã§alÄ±ÅŸmazsa sistem Ã§Ã¶kmez
    - Karar Ã¼retmez, sadece bilgilendirir
    """

    if not DATA_FILE.exists():
        return {
            "decision": "no_data",
            "multiplier": 1.0,
            "reason": "HenÃ¼z geri bildirim verisi yok."
        }

    with open(DATA_FILE, "r", encoding="utf-8") as f:
        data = json.load(f)

    feedbacks = [d for d in data if d.get("type") == "feedback"]
    if not feedbacks:
        return {
            "decision": "no_feedback",
            "multiplier": 1.0,
            "reason": "HenÃ¼z geri bildirim yok."
        }

    last_feedback = feedbacks[-1]

    prompt = f"""
Sen oldukÃ§a rasyonel, sonuÃ§ odaklÄ± ve gerektiÄŸinde "ACIMASIZ" bir Ã‡ALIÅMA KOORDÄ°NATÃ–RÃœ etmensin. 
Ã–ÄŸrencinin iyiliÄŸi iÃ§in planÄ± radikal ÅŸekilde deÄŸiÅŸtirmekten Ã§ekinmezsin.

AÅŸaÄŸÄ±daki geri bildirime gÃ¶re Ã§alÄ±ÅŸma planÄ±nÄ±n yoÄŸunluÄŸunu deÄŸerlendir. 

Kurallar:
- EÄŸer Ã¶ÄŸrenci Ã§ok zorlanÄ±yorsa veya verimliliÄŸi Ã§ok dÃ¼ÅŸÃ¼kse multiplier deÄŸerini sert bir ÅŸekilde dÃ¼ÅŸÃ¼r (Ã¶rn: 0.4 - 0.6).
- EÄŸer Ã¶ÄŸrenci Ã§ok rahatsa ve daha fazlasÄ±nÄ± yapabilecekse multiplier deÄŸerini artÄ±r (Ã¶rn: 1.3 - 1.6).
- Sadece saatleri deÄŸil, Ã¶ÄŸrencinin mental durumunu da gÃ¶zet ama plana sadÄ±k kalmasÄ± iÃ§in en optimize kararÄ± ver.

SADECE JSON DÃ–NDÃœR:

{{
  "decision": "increase | decrease | keep",
  "multiplier": 0.3 ile 2.0 arasÄ±nda bir sayÄ±,
  "reason": "kÄ±sa ve Ã¶z otoriter gerekÃ§e"
}}

GERÄ° BÄ°LDÄ°RÄ°M:
{json.dumps(last_feedback, ensure_ascii=False)}
"""

    try:
        raw = client.generate(prompt)
        return _safe_json_parse(raw)

    except Exception:
        # ğŸ”’ LLM yok â†’ sistem Ã§Ã¶kmez ama karar da Ã¼retmez
        return {
            "decision": "unknown",
            "multiplier": 1.0,
            "reason": "LLM eriÅŸilemediÄŸi iÃ§in koordinatÃ¶r kararÄ± Ã¼retilemedi."
        }
